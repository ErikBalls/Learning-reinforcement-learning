{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a689a0-3a4b-4c94-82e6-75db8ee34514",
   "metadata": {},
   "source": [
    "# Required installations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4b869-aad0-4315-94c3-0da007b1744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "#!pip install keras-rl2\n",
    "#!pip install gym\n",
    "#!pip install matplotlib\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install stable_baselines3[extra]\n",
    "#!pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d072cf-ae20-4c31-876d-5d8e0d794324",
   "metadata": {},
   "source": [
    "# Important imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6661bdf4-51cf-4bf3-9bd0-a18d8edcf21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DDPG, TD3, A2C, PPO\n",
    "from stable_baselines3.common.noise import NormalActionNoise #importing Gaussian Noise\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838977a9-d5b9-4786-9031-676269a0727f",
   "metadata": {},
   "source": [
    "# Initializising environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6212b03e-f864-4688-acfe-0bd9526be97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample action [-0.02947027]\n",
      "observation space shape (3,)\n",
      "sample observation [-0.4079572   0.25272834 -0.5862485 ]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1', g = 9.81, render_mode=\"rgb_array\") #choose gym from https://gymnasium.farama.org/. Choose render mode \"rgb_array\" or choose \"human\" to visiualize the game but it will take more time until the action is done\n",
    "env.reset() #clear the environment\n",
    "\n",
    "print(\"sample action\", env.action_space.sample()) #Value for action\n",
    "print(\"observation space shape\", env.observation_space.shape) #Tensor for possible states (In pendulum there are 3 states of the pendulum: x-,y coordinate and angular velocity)\n",
    "print(\"sample observation\", env.observation_space.sample()) #Actual values inside the Tensor (Since there are 3 states of the pendulum, the tensor includes 3 values of the states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37958a9-83b6-4885-95ab-e518cf1f3719",
   "metadata": {},
   "source": [
    "# Let the game be played without any sense \n",
    "## (Don't forget \"human\" Render Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8306c-9d9a-4cc5-84ee-f4d1af9888f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10 #initialise for loop\n",
    "for episode in range(1, episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done: #what to do in the for loop\n",
    "        env.render() #render the process\n",
    "        action = env.action_space.sample() #what action can be taken\n",
    "        n_state, reward, terminated, truncated, info = env.step(action) #return of the parameters\n",
    "        score += reward #sum of the reward\n",
    "        done = terminated or truncated\n",
    "        \n",
    "    print(\"Episode:{} Score:{}\".format(episode, score)) #print the number and the reward of the episode\n",
    "    print(\"sample action\", env.action_space.sample()) #Value for action\n",
    "    print(\"sample observation\", env.observation_space.sample()) #Actual values inside the Tensor (Since there are 3 states of the pendulum, the tensor includes 3 values of the states)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc3494-d144-446d-921d-fd53eabb7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095baba-55dc-4bbe-a8b2-85639bd134c9",
   "metadata": {},
   "source": [
    "# Building, training and saving a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cab43be-7b24-4512-8f14-4e9a4510c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to logs\\Test_0\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.63e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 210       |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 30        |\n",
      "|    critic_loss     | 0.00997   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.48e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 211       |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 53.7      |\n",
      "|    critic_loss     | 0.03      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.34e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 208       |\n",
      "|    time_elapsed    | 11        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 70.6      |\n",
      "|    critic_loss     | 0.316     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.09e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 208       |\n",
      "|    time_elapsed    | 15        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 74        |\n",
      "|    critic_loss     | 0.294     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -887     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 206      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 70.5     |\n",
      "|    critic_loss     | 1.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -774     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 207      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 70.8     |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -668     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 207      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 70.1     |\n",
      "|    critic_loss     | 0.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -607     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 207      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 69.2     |\n",
      "|    critic_loss     | 1.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -553     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 207      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 58.8     |\n",
      "|    critic_loss     | 0.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -510     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 207      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 61       |\n",
      "|    critic_loss     | 1.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -482     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 206      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 59.6     |\n",
      "|    critic_loss     | 1.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -455     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 206      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 54.9     |\n",
      "|    critic_loss     | 1.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "Logging to logs\\Test_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -434     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 210      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 10400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 45.2     |\n",
      "|    critic_loss     | 0.884    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -416     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 206      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 11200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 41.7     |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -396     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 206      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 40.6     |\n",
      "|    critic_loss     | 0.774    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -379     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 205      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 12800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 41.2     |\n",
      "|    critic_loss     | 0.738    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12699    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m): \u001b[38;5;66;03m#for 60 times 10000 = 600000 steps the model will learn. The learning duration is 300000 steps\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mTIMESTEPS, reset_num_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tb_log_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#change the tb_log_name to create different folders in your explorer\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTIMESTEPS\u001b[38;5;241m*\u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#to see data in your tensorboard, open a terminal in your corresponding directory and type tensorboard --logdir=logs while the model is learning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    124\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    125\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    126\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    127\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    128\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    129\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    130\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    223\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    224\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    225\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    226\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    227\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    228\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    229\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, gradient_steps\u001b[38;5;241m=\u001b[39mgradient_steps)\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:188\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Optimize the critics\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 188\u001b[0m critic_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Delayed policy updates\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    523\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\torch\\autograd\\__init__.py:282\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    273\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    274\u001b[0m     (inputs,)\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    281\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 282\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Reinforcement_Learning\\Lib\\site-packages\\torch\\autograd\\__init__.py:161\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    155\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    160\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 161\u001b[0m         torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_dir = \"models/Test\" #making a Folder in your explorer with the data , dont forget to name your folder according to your model name\n",
    "logdir = \"logs\" \n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space.shape[0]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "model = DDPG(\"MlpPolicy\", env, verbose = 1, tensorboard_log=logdir, action_noise=action_noise) #defining model as DDPG/TD3/A2C/PPO Model with given policy, environment, verbose = 1 for returning infos, sending infos to tensorboard and the noise for better exploration\n",
    "#action_noise=action_noise cannot be applied to stochastic models like A2C or PPO!\n",
    "TIMESTEPS = 10000 #defining when a model will be saved, in this case every 10000 steps\n",
    "iters = 0\n",
    "for i in range(20): #for 20 times 10000 = 200000 steps the model will learn.\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"Test\") #change the tb_log_name to create different folders in your explorer\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")\n",
    "#to see data in your tensorboard, open a terminal in your corresponding directory and type \"tensorboard --logdir=logs\" while the model is learning\n",
    "#to load the data when you closed tensorboard type \"tensorboard --logdir path/to/logs\"\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22639143-018f-46e6-9cd6-f1cdc081c1bb",
   "metadata": {},
   "source": [
    "# Load the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b095c-9a84-4c33-8403-926129bd364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models/DDPG\"\n",
    "model_path = f\"{models_dir}/180000.zip\"\n",
    "logdir = \"logs\" \n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "env = gym.make('Pendulum-v1', g = 9.81, render_mode=\"human\") \n",
    "env.reset() \n",
    "\n",
    "\n",
    "\n",
    "model = DDPG.load(model_path, env = env)\n",
    "print(\"observation space shape\", env.observation_space.shape)\n",
    "episodes = 10\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs = env.observation_space.sample()\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90c84f-91b6-4f69-8630-a846fefe392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845e748-e7a3-43e3-bd20-770b65f1b56f",
   "metadata": {},
   "source": [
    "# Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333425c0-ed21-466f-a448-4ecc0b6c6ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "df_DDPG = pd.read_csv('logs_DDPG_w_o_noise_03.09.24_0.csv') #define your data logs here\n",
    "df_TD3 = pd.read_csv('logs_TD3_w_o_noise_03.09.24_0.csv')\n",
    "df_A2C = pd.read_csv('logs_A2C_03.09.24_0.csv')\n",
    "df_PPO = pd.read_csv('logs_PPO_03.09.24_0.csv')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "plt.scatter(df_DDPG.Step, df_DDPG.Value, marker = '.', color = 'red', s = 10, label='DDPG') #DIY your own diagram\n",
    "plt.scatter(df_TD3.Step, df_TD3.Value, marker = '.', color = 'blue', s = 10, label='TD3')\n",
    "plt.scatter(df_A2C.Step, df_A2C.Value, marker = '.', color = 'gray', s = 10, label='A2C')\n",
    "plt.scatter(df_PPO.Step, df_PPO.Value, marker = '.', color = 'black', s = 10, label='PPO')\n",
    "\n",
    "plt.title('Comparison of the models in the Pendelum environment', loc = 'left')\n",
    "\n",
    "max_value_DDPG = df_DDPG.Value.max() #defining max values of the data logs to compare the models\n",
    "max_step_DDPG = df_DDPG[df_DDPG.Value == max_value_DDPG].Step.values[0]\n",
    "max_value_TD3 = df_TD3.Value.max()\n",
    "max_step_TD3 = df_TD3[df_TD3.Value == max_value_TD3].Step.values[0]\n",
    "plt.scatter(max_step_DDPG, max_value_DDPG, color='red', s=30, marker='o')\n",
    "plt.annotate(f'Max: {max_value_DDPG:.2f}', (max_step_DDPG, max_value_DDPG), xytext=(125000, max_value_DDPG + -120), color = 'blue')\n",
    "plt.scatter(max_step_TD3, max_value_TD3, color='blue', s=30, marker='o')\n",
    "plt.annotate(f'Max: {max_value_TD3:.2f}', (max_step_TD3, max_value_TD3), xytext=(160000, max_value_DDPG + -120), color = 'red')\n",
    "#plt.annotate(f'Max: {max_step_TD3:.2f}', (max_step_TD3, max_value_TD3)) #check step when max reward was recieved\n",
    "#plt.annotate(f'Max: {max_step_DDPG:.2f}', (max_step_DDPG, max_value_DDPG)) #check step when max reward was recieved\n",
    "plt.axvline(x=max_step_DDPG, color='gray', linestyle='--', alpha = 0.5, dashes=(5, 10))\n",
    "plt.axvline(x=max_step_TD3, color='gray', linestyle='--', alpha = 0.5, dashes=(5, 10))\n",
    "\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Reward')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(-0.2, 0.91))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7352c-3044-430f-bf8c-36b351c054d2",
   "metadata": {},
   "source": [
    "#### We are going to compare the different trained models in the Pendulum environment. We can see the recieved reward of the models on the y-axis and the amount of steps taken on the x-axis. The most rewards recieved the TD3 model on approximatly 154000 steps. The second most rewards recieved the DDPG model on approximatly 189000 steps. \n",
    "#### Overall the DDPG and the TD3 model learned the Pendulum Environment pretty fast compared to the A2C and the PPO models. Thanks to the actor-critic-architecture of the DDPG and TD3 the agents can remember previous rewards of previous steps and learn from the past. The A2C and PPO agents have no memory by default. That's why the DDPG and TD3 agents learn faster than the A2C and PPO agents.\n",
    "#### The learning curve of the DDPG and TD3 model are similiar to each over but the learning curve of the DDPG model reached the convergence region faster than the TD3 model. This is because of the delayed critic network of the TD3 Agent (Or Twin Delayed DDPG Agent). In order to prevent greedy decisions of the actor the critic network updates itself less often than the DDPG critic. This can be a advantage in some cases but in this case this delayed the learning curve from reaching the convergence region.\n",
    "#### Summa summarum the DDPG and the TD3 model learned the environment fast and managed to solve the task. The A2C and PPO models have to be trained more steps in order to learn what to do with the pendulum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87693786-098a-47a4-91a4-29f8ad492f38",
   "metadata": {},
   "source": [
    "# Using a custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59ca73-0452-48f7-8bfc-8af6c537a8d4",
   "metadata": {},
   "source": [
    "#### Let's explore a custom environment for our next challenge. We'll simulate a Permanent Magnet Synchronous Motor (PMSM) and train two agents, DDPG and TD3, to control the motor's current, with the objective of maximizing torque output. Thankfully clever people have already developed a custom environment for this simulation. In this section, we'll follow the approach outlined on the Gym Electric Motor (GEM) GitHub page. For more detailed information, visit: https://github.com/upb-lea/gym-electric-motor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "951ffd16-a665-4da5-8c52-99f7edca1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym-electric-motor\n",
      "  Downloading gym_electric_motor-2.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: matplotlib>=3.1.2 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gym-electric-motor) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.16.4 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gym-electric-motor) (1.26.3)\n",
      "Collecting scipy>=1.4.1 (from gym-electric-motor)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting gym<0.24.0,>=0.15.4 (from gym-electric-motor)\n",
      "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
      "     ---------------------------------------- 0.0/626.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 626.2/626.2 kB 11.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytest>=5.2.2 (from gym-electric-motor)\n",
      "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pytest-cov (from gym-electric-motor)\n",
      "  Downloading pytest_cov-5.0.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: gymnasium>=0.29.0 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gym-electric-motor) (0.29.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gym<0.24.0,>=0.15.4->gym-electric-motor) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gym<0.24.0,>=0.15.4->gym-electric-motor) (0.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gymnasium>=0.29.0->gym-electric-motor) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from gymnasium>=0.29.0->gym-electric-motor) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from matplotlib>=3.1.2->gym-electric-motor) (2.9.0.post0)\n",
      "Collecting iniconfig (from pytest>=5.2.2->gym-electric-motor)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest>=5.2.2->gym-electric-motor)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from pytest>=5.2.2->gym-electric-motor) (0.4.6)\n",
      "Collecting coverage>=5.2.1 (from coverage[toml]>=5.2.1->pytest-cov->gym-electric-motor)\n",
      "  Downloading coverage-7.6.1-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kirit\\anaconda3\\envs\\reinforcement_learning\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1.2->gym-electric-motor) (1.16.0)\n",
      "Downloading gym_electric_motor-2.0.0-py3-none-any.whl (393 kB)\n",
      "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/44.8 MB 12.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.0/44.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.6/44.8 MB 12.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 10.5/44.8 MB 12.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.1/44.8 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 15.7/44.8 MB 12.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.4/44.8 MB 12.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.0/44.8 MB 12.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.6/44.8 MB 12.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.2/44.8 MB 12.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.1/44.8 MB 12.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.7/44.8 MB 12.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.3/44.8 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.0/44.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.6/44.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.2/44.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 12.5 MB/s eta 0:00:00\n",
      "Downloading pytest_cov-5.0.0-py3-none-any.whl (21 kB)\n",
      "Downloading coverage-7.6.1-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701360 sha256=ab56e4850f44e1a2bcab5b440d0234df6b2a20a09a5a0038bbc86f4126c3318c\n",
      "  Stored in directory: c:\\users\\kirit\\appdata\\local\\pip\\cache\\wheels\\5b\\dd\\a4\\b1860cec4c1751b5a84c31e2abc3b88bd71e11c1df79b73986\n",
      "Successfully built gym\n",
      "Installing collected packages: scipy, pluggy, iniconfig, gym, coverage, pytest, pytest-cov, gym-electric-motor\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 1.0.0\n",
      "    Uninstalling pluggy-1.0.0:\n",
      "      Successfully uninstalled pluggy-1.0.0\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed coverage-7.6.1 gym-0.23.1 gym-electric-motor-2.0.0 iniconfig-2.0.0 pluggy-1.5.0 pytest-8.3.3 pytest-cov-5.0.0 scipy-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gym-electric-motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63c4657c-acf3-45c9-9535-d75a8145960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_electric_motor as gem\n",
    "from gym_electric_motor.reference_generators import LaplaceProcessReferenceGenerator\n",
    "from gym_electric_motor.visualization import MotorDashboard\n",
    "from gym_electric_motor.core import Callback\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "from gymnasium.wrappers import FlattenObservation, TimeLimit\n",
    "from gymnasium import ObservationWrapper\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "49574842-6529-4901-821c-623a3dd755d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardLogger(Callback): \n",
    "    \"\"\"Logs the reward accumulated in each episode\"\"\"\n",
    "    def __init__(self):\n",
    "        self.step_rewards = []\n",
    "        self.mean_episode_rewards = []\n",
    "        dir_path = Path.cwd() /\"PMSM_simulation\" / \"saved_agents\" #change directory names as you wish\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.fpath = dir_path  / \"EpisodeRewards.npy\"\n",
    "        \n",
    "    def on_step_end(self, k, state, reference, reward, done):\n",
    "        \"\"\"Stores the received reward at each step\"\"\"\n",
    "        self.step_rewards.append(reward)\n",
    "    \n",
    "    def on_reset_begin(self):\n",
    "        \"\"\"Stores the mean reward received in every episode\"\"\"\n",
    "        if len(self.step_rewards) > 0:\n",
    "            self.mean_episode_rewards.append(np.mean(self.step_rewards))\n",
    "        self.step_rewards = []\n",
    "        \n",
    "    def on_close(self):\n",
    "        \"\"\"Writes the mean episode reward of the experiment to a file.\"\"\"\n",
    "        np.save(self.fpath, np.array(self.mean_episode_rewards))\n",
    "\n",
    "class FeatureWrapper(ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Wrapper class which wraps the environment to change its observation. Serves\n",
    "    the purpose to improve the agent's learning speed.\n",
    "    \n",
    "    It changes epsilon to cos(epsilon) and sin(epsilon). This serves the purpose\n",
    "    to have the angles -pi and pi close to each other numerically without losing\n",
    "    any information on the angle.\n",
    "    \n",
    "    Additionally, this wrapper adds a new observation i_sd**2 + i_sq**2. This should\n",
    "    help the agent to easier detect incoming limit violations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, epsilon_idx, i_sd_idx, i_sq_idx):\n",
    "        \"\"\"\n",
    "        Changes the observation space to fit the new features\n",
    "        \n",
    "        Args:\n",
    "            env(GEM env): GEM environment to wrap\n",
    "            epsilon_idx(integer): Epsilon's index in the observation array\n",
    "            i_sd_idx(integer): I_sd's index in the observation array\n",
    "            i_sq_idx(integer): I_sq's index in the observation array\n",
    "        \"\"\"\n",
    "        super(FeatureWrapper, self).__init__(env)\n",
    "        self.EPSILON_IDX = epsilon_idx\n",
    "        self.I_SQ_IDX = i_sq_idx\n",
    "        self.I_SD_IDX = i_sd_idx\n",
    "        new_low = np.concatenate((self.env.observation_space.low[     \n",
    "                                  :self.EPSILON_IDX], np.array([-1.]),\n",
    "                                  self.env.observation_space.low[\n",
    "                                  self.EPSILON_IDX:], np.array([0.])))\n",
    "        new_high = np.concatenate((self.env.observation_space.high[\n",
    "                                   :self.EPSILON_IDX], np.array([1.]),\n",
    "                                   self.env.observation_space.high[\n",
    "                                   self.EPSILON_IDX:],np.array([1.])))\n",
    "\n",
    "        self.observation_space = Box(new_low, new_high)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        \"\"\"\n",
    "        Gets called at each return of an observation. Adds the new features to the\n",
    "        observation and removes original epsilon.\n",
    "        \n",
    "        \"\"\"\n",
    "        cos_eps = np.cos(observation[self.EPSILON_IDX] * np.pi)\n",
    "        sin_eps = np.sin(observation[self.EPSILON_IDX] * np.pi)\n",
    "        currents_squared = observation[self.I_SQ_IDX]**2 + observation[self.I_SD_IDX]**2\n",
    "        observation = np.concatenate((observation[:self.EPSILON_IDX],\n",
    "                                      np.array([cos_eps, sin_eps]),\n",
    "                                      observation[self.EPSILON_IDX + 1:],\n",
    "                                      np.array([currents_squared])))\n",
    "        return observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "68376181-eecd-4ea9-bbe6-e1b94035b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "# define motor arguments\n",
    "motor_parameter = dict(\n",
    "    p=3,  # [p] = 1, nb of pole pairs\n",
    "    r_s=17.932e-3,  # [r_s] = Ohm, stator resistance\n",
    "    l_d=0.37e-3,  # [l_d] = H, d-axis inductance\n",
    "    l_q=1.2e-3,  # [l_q] = H, q-axis inductance\n",
    "    psi_p=65.65e-3,  # [psi_p] = Vs, magnetic flux of the permanent magnet\n",
    ")\n",
    "# supply voltage\n",
    "my_changed_voltage_supply_args = {'u': 400.0},\n",
    "\n",
    "# Replace the reference generator by passing a new instance\n",
    "my_new_ref_gen_instance = LaplaceProcessReferenceGenerator(\n",
    "    reference_state='i_sq',\n",
    "    sigma_range=(1e-3, 1e-2)\n",
    ")\n",
    "\n",
    "# nominal and absolute state limitations\n",
    "nominal_values=dict(\n",
    "    omega=418.879,\n",
    "    i=230,\n",
    "    u=400.0\n",
    ")\n",
    "limit_values=dict(\n",
    "    omega=418.879,\n",
    "    i=345,\n",
    "    u=400.0\n",
    ")\n",
    "\n",
    "# sampling interval\n",
    "tau = 1e-5\n",
    "\n",
    "# define maximal episode steps\n",
    "max_eps_steps = 10000\n",
    "\n",
    "# Select a different ode_solver with default parameters by passing a keystring\n",
    "#my_overridden_solver = 'scipy-solve_ivp', \n",
    "\n",
    "\n",
    "motor_initializer = {'random_init': 'uniform', 'interval': np.array([[-230, 230], [-230, 230], [-np.pi, np.pi]])}\n",
    "reward_function=gem.reward_functions.WeightedSumOfErrors(\n",
    "    reward_weights={'i_sq': 10, 'i_sd': 10},\n",
    "    gamma=0.99,  # discount rate \n",
    "    reward_power=1\n",
    ")\n",
    "reward_logger = RewardLogger()\n",
    "motor_dashboard = MotorDashboard(state_plots=['i_sq', 'i_sd'], reward_plot=True)\n",
    "# creating gem environment\n",
    "env = gem.make(  # define a PMSM with discrete action space\n",
    "    'Cont-CC-PMSM-v0',\n",
    "    # visualize the results\n",
    "    visualization=motor_dashboard,\n",
    "    voltage_supply=my_changed_voltage_supply_args,\n",
    "    reference_generator=my_new_ref_gen_instance,\n",
    "    \n",
    "    # parameterize the PMSM and update limitations\n",
    "    motor=dict(\n",
    "        motor_parameter=motor_parameter,\n",
    "        limit_values=limit_values,\n",
    "        nominal_values=nominal_values,\n",
    "        motor_initializer=motor_initializer,\n",
    "    ),\n",
    "    # define the random initialisation for load and motor\n",
    "    load=dict(\n",
    "        load_initializer={'random_init': 'uniform', },\n",
    "    ),\n",
    "    reward_function=reward_function,\n",
    "    supply=dict(u_nominal=u_supply),\n",
    "    # define the duration of one sampling step\n",
    "    tau=tau,\n",
    "    callbacks=(reward_logger,),\n",
    "    ode_solver='euler',\n",
    ")\n",
    "\n",
    "# remove one action from the action space to help the agent speed up its training\n",
    "# this can be done as both switchting states (1,1,1) and (-1,-1,-1) - which are encoded\n",
    "# by action 0 and 7 - both lead to the same zero voltage vector in alpha/beta-coordinates\n",
    "env.action_space = Box(low=np.array([-1.0, -1.0, -1.0]), high=np.array([1.0, 1.0, 1.0]), dtype=np.float32) #Discrete(8)\n",
    "\n",
    "# applying wrappers\n",
    "eps_idx = env.physical_system.state_names.index('epsilon')\n",
    "i_sd_idx = env.physical_system.state_names.index('i_sd')\n",
    "i_sq_idx = env.physical_system.state_names.index('i_sq')\n",
    "env = TimeLimit(\n",
    "    FeatureWrapper(\n",
    "        FlattenObservation(env), \n",
    "        eps_idx, i_sd_idx, i_sq_idx\n",
    "    ),\n",
    "    max_eps_steps\n",
    ")\n",
    "print(env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "05bfedf3-b9b2-47f3-80fa-38b9bd7013f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 200000 #number of old obsersation steps saved\n",
    "learning_starts = 10000 # memory warmup\n",
    "train_freq = 1 # prediction network gets an update each train_freq's step\n",
    "batch_size = 25 # mini batch size drawn at each update step\n",
    "policy_kwargs = {\n",
    "        'net_arch': [64,64] # hidden layer size of MLP\n",
    "        }\n",
    "exploration_fraction = 0.1 # Fraction of training steps the epsilon decays \n",
    "target_update_interval = 1000 # Target network gets updated each target_update_interval's step\n",
    "gamma = 0.99\n",
    "verbose = 1 # verbosity of stable-basline's prints\n",
    "tau = 1e-5\n",
    "simulation_time = 5 # seconds\n",
    "nb_steps = int(simulation_time // tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "47acc6fe-46ed-4fa0-8db7-5f02c58b188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to PMSM_simulation/logs\\DDPG_PMSM_0\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.78e+03  |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 1200      |\n",
      "|    time_elapsed    | 9         |\n",
      "|    total_timesteps | 11137     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 17        |\n",
      "|    critic_loss     | 0.102     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1136      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -7.73e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 12539     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 32.6      |\n",
      "|    critic_loss     | 2.65      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2538      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -6.36e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 565       |\n",
      "|    time_elapsed    | 24        |\n",
      "|    total_timesteps | 14070     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 49.5      |\n",
      "|    critic_loss     | 7.95      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 4069      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -6.88e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 325       |\n",
      "|    time_elapsed    | 67        |\n",
      "|    total_timesteps | 22060     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 49.8      |\n",
      "|    critic_loss     | 44.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12059     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -7.42e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 268       |\n",
      "|    time_elapsed    | 114       |\n",
      "|    total_timesteps | 30828     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 32        |\n",
      "|    critic_loss     | 12.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20827     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -8.18e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 234       |\n",
      "|    time_elapsed    | 182       |\n",
      "|    total_timesteps | 42877     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 71.2      |\n",
      "|    critic_loss     | 3.58      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 32876     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -8.33e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 226       |\n",
      "|    time_elapsed    | 221       |\n",
      "|    total_timesteps | 50136     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 164       |\n",
      "|    critic_loss     | 18.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 40135     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -8.83e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 219       |\n",
      "|    time_elapsed    | 273       |\n",
      "|    total_timesteps | 60010     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 111       |\n",
      "|    critic_loss     | 14.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 50009     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -8.47e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 217       |\n",
      "|    time_elapsed    | 291       |\n",
      "|    total_timesteps | 63329     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 163       |\n",
      "|    critic_loss     | 36.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 53328     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -9.55e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 207       |\n",
      "|    time_elapsed    | 380       |\n",
      "|    total_timesteps | 79124     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 93.8      |\n",
      "|    critic_loss     | 10.6      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 69123     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.12e+03  |\n",
      "|    ep_rew_mean     | -9.76e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 201       |\n",
      "|    time_elapsed    | 462       |\n",
      "|    total_timesteps | 93289     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 66.2      |\n",
      "|    critic_loss     | 5.65      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 83288     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.19e+03  |\n",
      "|    ep_rew_mean     | -9.93e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 198       |\n",
      "|    time_elapsed    | 530       |\n",
      "|    total_timesteps | 105203    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 108       |\n",
      "|    critic_loss     | 44.2      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 95202     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.17e+03  |\n",
      "|    ep_rew_mean     | -9.79e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 196       |\n",
      "|    time_elapsed    | 574       |\n",
      "|    total_timesteps | 113025    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 124       |\n",
      "|    critic_loss     | 33.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 103024    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.24e+03  |\n",
      "|    ep_rew_mean     | -9.86e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 194       |\n",
      "|    time_elapsed    | 645       |\n",
      "|    total_timesteps | 125430    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38.3      |\n",
      "|    critic_loss     | 5.56      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 115429    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.18e+03 |\n",
      "|    ep_rew_mean     | -9.6e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 193      |\n",
      "|    time_elapsed    | 676      |\n",
      "|    total_timesteps | 130691   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 43.3     |\n",
      "|    critic_loss     | 5.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 120690   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.14e+03  |\n",
      "|    ep_rew_mean     | -9.51e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 64        |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 714       |\n",
      "|    total_timesteps | 137225    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 82.8      |\n",
      "|    critic_loss     | 7.86      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 127224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.11e+03  |\n",
      "|    ep_rew_mean     | -9.38e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 68        |\n",
      "|    fps             | 191       |\n",
      "|    time_elapsed    | 749       |\n",
      "|    total_timesteps | 143265    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 127       |\n",
      "|    critic_loss     | 43.2      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 133264    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -9.13e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 72        |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 767       |\n",
      "|    total_timesteps | 146387    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 166       |\n",
      "|    critic_loss     | 9.09      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 136386    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -8.81e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 76        |\n",
      "|    fps             | 190       |\n",
      "|    time_elapsed    | 774       |\n",
      "|    total_timesteps | 147474    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 93.1      |\n",
      "|    critic_loss     | 64.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 137473    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -8.81e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 80        |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 818       |\n",
      "|    total_timesteps | 155346    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 150       |\n",
      "|    critic_loss     | 8.47e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 145345    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -8.75e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 84        |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 859       |\n",
      "|    total_timesteps | 163179    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 118       |\n",
      "|    critic_loss     | 94.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 153178    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.96e+03  |\n",
      "|    ep_rew_mean     | -8.74e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 88        |\n",
      "|    fps             | 189       |\n",
      "|    time_elapsed    | 908       |\n",
      "|    total_timesteps | 172466    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 93        |\n",
      "|    critic_loss     | 17.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 162465    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.08e+03 |\n",
      "|    ep_rew_mean     | -9e+03   |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 189      |\n",
      "|    time_elapsed    | 1011     |\n",
      "|    total_timesteps | 191482   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 137      |\n",
      "|    critic_loss     | 233      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 181481   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.04e+03  |\n",
      "|    ep_rew_mean     | -8.87e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 96        |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 1033      |\n",
      "|    total_timesteps | 195377    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 116       |\n",
      "|    critic_loss     | 17.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 185376    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.09e+03  |\n",
      "|    ep_rew_mean     | -9.05e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 100       |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 1106      |\n",
      "|    total_timesteps | 208604    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 95.5      |\n",
      "|    critic_loss     | 27.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 198603    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.25e+03  |\n",
      "|    ep_rew_mean     | -9.42e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 104       |\n",
      "|    fps             | 184       |\n",
      "|    time_elapsed    | 1274      |\n",
      "|    total_timesteps | 235703    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 194       |\n",
      "|    critic_loss     | 12.5      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 225702    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.46e+03 |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 182      |\n",
      "|    time_elapsed    | 1412     |\n",
      "|    total_timesteps | 258433   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 173      |\n",
      "|    critic_loss     | 38.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 248432   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.57e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 112       |\n",
      "|    fps             | 182       |\n",
      "|    time_elapsed    | 1490      |\n",
      "|    total_timesteps | 271507    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 124       |\n",
      "|    critic_loss     | 21.8      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 261506    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.58e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 116       |\n",
      "|    fps             | 181       |\n",
      "|    time_elapsed    | 1536      |\n",
      "|    total_timesteps | 279566    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 132       |\n",
      "|    critic_loss     | 4.79      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 269565    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.57e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 120       |\n",
      "|    fps             | 181       |\n",
      "|    time_elapsed    | 1583      |\n",
      "|    total_timesteps | 287516    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 137       |\n",
      "|    critic_loss     | 376       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 277515    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.56e+03  |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 124       |\n",
      "|    fps             | 181       |\n",
      "|    time_elapsed    | 1649      |\n",
      "|    total_timesteps | 298854    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 140       |\n",
      "|    critic_loss     | 8.64      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 288853    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.58e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 128       |\n",
      "|    fps             | 180       |\n",
      "|    time_elapsed    | 1705      |\n",
      "|    total_timesteps | 308388    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 128       |\n",
      "|    critic_loss     | 26.2      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 298387    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.64e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 132       |\n",
      "|    fps             | 180       |\n",
      "|    time_elapsed    | 1795      |\n",
      "|    total_timesteps | 323712    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 99.8      |\n",
      "|    critic_loss     | 13        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 313711    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.63e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 136       |\n",
      "|    fps             | 180       |\n",
      "|    time_elapsed    | 1808      |\n",
      "|    total_timesteps | 325984    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 156       |\n",
      "|    critic_loss     | 24.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 315983    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.61e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 140       |\n",
      "|    fps             | 179       |\n",
      "|    time_elapsed    | 1893      |\n",
      "|    total_timesteps | 340450    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 135       |\n",
      "|    critic_loss     | 11.5      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 330449    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.56e+03  |\n",
      "|    ep_rew_mean     | -1.01e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 144       |\n",
      "|    fps             | 179       |\n",
      "|    time_elapsed    | 1943      |\n",
      "|    total_timesteps | 348800    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 140       |\n",
      "|    critic_loss     | 34.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 338799    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.46e+03  |\n",
      "|    ep_rew_mean     | -9.73e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 148       |\n",
      "|    fps             | 179       |\n",
      "|    time_elapsed    | 1959      |\n",
      "|    total_timesteps | 351529    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 135       |\n",
      "|    critic_loss     | 13.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 341528    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.42e+03  |\n",
      "|    ep_rew_mean     | -9.58e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 152       |\n",
      "|    fps             | 179       |\n",
      "|    time_elapsed    | 1981      |\n",
      "|    total_timesteps | 355208    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 157       |\n",
      "|    critic_loss     | 26.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 345207    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.32e+03  |\n",
      "|    ep_rew_mean     | -9.31e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 156       |\n",
      "|    fps             | 179       |\n",
      "|    time_elapsed    | 1996      |\n",
      "|    total_timesteps | 357640    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 154       |\n",
      "|    critic_loss     | 31.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 347639    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -9.47e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 160       |\n",
      "|    fps             | 178       |\n",
      "|    time_elapsed    | 2073      |\n",
      "|    total_timesteps | 370405    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 137       |\n",
      "|    critic_loss     | 8.21      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 360404    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.37e+03  |\n",
      "|    ep_rew_mean     | -9.34e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 164       |\n",
      "|    fps             | 178       |\n",
      "|    time_elapsed    | 2098      |\n",
      "|    total_timesteps | 374440    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 156       |\n",
      "|    critic_loss     | 8.01      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 364439    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.44e+03  |\n",
      "|    ep_rew_mean     | -9.68e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 168       |\n",
      "|    fps             | 176       |\n",
      "|    time_elapsed    | 2191      |\n",
      "|    total_timesteps | 387610    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 146       |\n",
      "|    critic_loss     | 21.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 377609    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.53e+03  |\n",
      "|    ep_rew_mean     | -9.94e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 172       |\n",
      "|    fps             | 175       |\n",
      "|    time_elapsed    | 2279      |\n",
      "|    total_timesteps | 399730    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 187       |\n",
      "|    critic_loss     | 7.38      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 389729    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.71e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 176       |\n",
      "|    fps             | 172       |\n",
      "|    time_elapsed    | 2418      |\n",
      "|    total_timesteps | 418051    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 112       |\n",
      "|    critic_loss     | 13.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 408050    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.79e+03  |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 180       |\n",
      "|    fps             | 170       |\n",
      "|    time_elapsed    | 2542      |\n",
      "|    total_timesteps | 433859    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 185       |\n",
      "|    critic_loss     | 8.24      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 423858    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.89e+03  |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 184       |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 2683      |\n",
      "|    total_timesteps | 452027    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 142       |\n",
      "|    critic_loss     | 14.8      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 442026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.94e+03  |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 188       |\n",
      "|    fps             | 166       |\n",
      "|    time_elapsed    | 2796      |\n",
      "|    total_timesteps | 466682    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 161       |\n",
      "|    critic_loss     | 12.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 456681    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.87e+03 |\n",
      "|    ep_rew_mean     | -1.1e+04 |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 165      |\n",
      "|    time_elapsed    | 2890     |\n",
      "|    total_timesteps | 478702   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 147      |\n",
      "|    critic_loss     | 85.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 468701   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 3.01e+03  |\n",
      "|    ep_rew_mean     | -1.14e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 196       |\n",
      "|    fps             | 163       |\n",
      "|    time_elapsed    | 3026      |\n",
      "|    total_timesteps | 496251    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 155       |\n",
      "|    critic_loss     | 10.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 486250    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dir_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mnb_steps, reset_num_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tb_log_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDDPG_PMSM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_timesteps\u001b[38;5;241m*\u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dir_path' is not defined"
     ]
    }
   ],
   "source": [
    "logdir = \"PMSM_simulation/logs\"\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, buffer_size=buffer_size, learning_starts=learning_starts ,train_freq=train_freq, \n",
    "            batch_size=batch_size, gamma=gamma, policy_kwargs=policy_kwargs, \n",
    "            verbose=verbose, tensorboard_log=logdir)\n",
    "\n",
    "for i in range(20):\n",
    "    model.learn(total_timesteps=nb_steps, reset_num_timesteps=False, tb_log_name=\"DDPG_PMSM\")\n",
    "    model.save(f\"{dir_path}/{total_timesteps*i}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c185b43-83bf-41e3-b121-8ecb5302f97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
